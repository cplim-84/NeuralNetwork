{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Deep Learning in Python - Credit Card Fraud Detection\n",
    "\n",
    "\n",
    "### Developing a Deep Neural Network in Keras to Predict and Classify Credit Card Transactions into Fraud or Non-Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the pandas package into this Jupyter notebook and refer it as pd\n",
    "\n",
    "\n",
    "2. Import the numpy package into this Jupyter notebook and refer it as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas** is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python.\n",
    "\n",
    "\n",
    "**NumPy** is the fundamental package for scientific computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and load credit card fraud data into Pandas dataframe and name it as df\n",
    "\n",
    "df = pd.read_csv('C:/data/creditcard_historical_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXNid</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TXNA0000001</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.110880</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.517144</td>\n",
       "      <td>1.325407</td>\n",
       "      <td>-0.191573</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>0.117620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037709</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>-0.048198</td>\n",
       "      <td>0.232115</td>\n",
       "      <td>0.606201</td>\n",
       "      <td>-0.342097</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TXNA0000002</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.249055</td>\n",
       "      <td>-0.624727</td>\n",
       "      <td>-0.710589</td>\n",
       "      <td>-0.991600</td>\n",
       "      <td>1.429973</td>\n",
       "      <td>3.692977</td>\n",
       "      <td>-1.090209</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006293</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>-0.129463</td>\n",
       "      <td>1.112970</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>1.196549</td>\n",
       "      <td>-0.048220</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>29.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TXNA0000003</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-2.008872</td>\n",
       "      <td>2.198527</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>1.159432</td>\n",
       "      <td>-0.815174</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>-0.617108</td>\n",
       "      <td>1.530817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.294983</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>-0.236141</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TXNA0000004</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.607877</td>\n",
       "      <td>1.031345</td>\n",
       "      <td>1.740450</td>\n",
       "      <td>1.232106</td>\n",
       "      <td>0.418592</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.850893</td>\n",
       "      <td>-0.176267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087329</td>\n",
       "      <td>0.258315</td>\n",
       "      <td>-0.264775</td>\n",
       "      <td>0.118282</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-0.217041</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>-0.033041</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TXNA0000005</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.935732</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>2.746261</td>\n",
       "      <td>-1.077965</td>\n",
       "      <td>-0.305594</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>-0.296178</td>\n",
       "      <td>0.402776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>1.064864</td>\n",
       "      <td>-0.158325</td>\n",
       "      <td>0.295505</td>\n",
       "      <td>-0.259370</td>\n",
       "      <td>0.754195</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.093948</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284332</td>\n",
       "      <td>TXNA0284333</td>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284333</td>\n",
       "      <td>TXNA0284334</td>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284334</td>\n",
       "      <td>TXNA0284335</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284335</td>\n",
       "      <td>TXNA0284336</td>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284336</td>\n",
       "      <td>TXNA0284337</td>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284337 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TXNid      Time         V1         V2        V3        V4  \\\n",
       "0       TXNA0000001      29.0   1.110880   0.168717  0.517144  1.325407   \n",
       "1       TXNA0000002      32.0   1.249055  -0.624727 -0.710589 -0.991600   \n",
       "2       TXNA0000003      32.0  -2.008872   2.198527  0.144242  1.159432   \n",
       "3       TXNA0000004      33.0  -0.607877   1.031345  1.740450  1.232106   \n",
       "4       TXNA0000005      33.0  -0.935732   0.170416  2.746261 -1.077965   \n",
       "...             ...       ...        ...        ...       ...       ...   \n",
       "284332  TXNA0284333  172786.0 -11.881118  10.071785 -9.834783 -2.066656   \n",
       "284333  TXNA0284334  172787.0  -0.732789  -0.055080  2.035030 -0.738589   \n",
       "284334  TXNA0284335  172788.0   1.919565  -0.301254 -3.249640 -0.557828   \n",
       "284335  TXNA0284336  172788.0  -0.240440   0.530483  0.702510  0.689799   \n",
       "284336  TXNA0284337  172792.0  -0.533413  -0.189733  0.703337 -0.506271   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V21       V22  \\\n",
       "0      -0.191573  0.019504 -0.031849  0.117620  ... -0.037709  0.095701   \n",
       "1       1.429973  3.692977 -1.090209  0.967291  ... -0.006293  0.009200   \n",
       "2      -0.815174  0.182288 -0.617108  1.530817  ...  0.094917  0.294983   \n",
       "3       0.418592  0.119168  0.850893 -0.176267  ... -0.087329  0.258315   \n",
       "4      -0.305594  0.011577 -0.296178  0.402776  ...  0.401212  1.064864   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284332 -5.364473 -2.606837 -4.918215  7.305334  ...  0.213454  0.111864   \n",
       "284333  0.868229  1.058415  0.024330  0.294869  ...  0.214205  0.924384   \n",
       "284334  2.630515  3.031260 -0.296827  0.708417  ...  0.232045  0.578229   \n",
       "284335 -0.377961  0.623708 -0.686180  0.679145  ...  0.265245  0.800049   \n",
       "284336 -0.012546 -0.649617  1.577006 -0.414650  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.048198  0.232115  0.606201 -0.342097  0.036770  0.007480    6.54   \n",
       "1      -0.129463  1.112970  0.500382  1.196549 -0.048220  0.005094   29.89   \n",
       "2       0.011081  0.015249  0.034211 -0.236141  0.128291  0.117986    2.35   \n",
       "3      -0.264775  0.118282  0.173508 -0.217041  0.094312 -0.033041   14.80   \n",
       "4      -0.158325  0.295505 -0.259370  0.754195  0.046664  0.093948    9.10   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284332  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284333  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284334 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284335 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284336  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284332      0  \n",
       "284333      0  \n",
       "284334      0  \n",
       "284335      0  \n",
       "284336      0  \n",
       "\n",
       "[284337 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Time</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>94797.597397</td>\n",
       "      <td>47472.343458</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>54208.000000</td>\n",
       "      <td>84666.000000</td>\n",
       "      <td>139293.000000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V1</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>1.958362</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920439</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315499</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V2</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>1.651311</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598655</td>\n",
       "      <td>0.065416</td>\n",
       "      <td>0.803687</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V3</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>1.514942</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.889801</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>1.027518</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V4</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>1.415447</td>\n",
       "      <td>-5.600607</td>\n",
       "      <td>-0.848668</td>\n",
       "      <td>-0.019838</td>\n",
       "      <td>0.743303</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V5</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000112</td>\n",
       "      <td>1.380077</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691700</td>\n",
       "      <td>-0.054592</td>\n",
       "      <td>0.611678</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V6</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>1.332412</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768212</td>\n",
       "      <td>-0.274148</td>\n",
       "      <td>0.398659</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V7</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.235462</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554147</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.570272</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V8</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>1.192689</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208555</td>\n",
       "      <td>0.022368</td>\n",
       "      <td>0.327404</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V9</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>1.098555</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.642983</td>\n",
       "      <td>-0.051224</td>\n",
       "      <td>0.597469</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V10</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>1.087753</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535584</td>\n",
       "      <td>-0.092985</td>\n",
       "      <td>0.453821</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V11</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.020488</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762356</td>\n",
       "      <td>-0.032711</td>\n",
       "      <td>0.739596</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V12</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.998749</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405776</td>\n",
       "      <td>0.139945</td>\n",
       "      <td>0.618100</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V13</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.995459</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648413</td>\n",
       "      <td>-0.013392</td>\n",
       "      <td>0.662790</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V14</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.957689</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425512</td>\n",
       "      <td>0.050674</td>\n",
       "      <td>0.493281</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V15</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.915325</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582896</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648836</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V16</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.467948</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.523392</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V17</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.848488</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483652</td>\n",
       "      <td>-0.065570</td>\n",
       "      <td>0.399762</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V18</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.838066</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498800</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V19</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.813940</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456226</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.458972</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V20</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.771187</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211693</td>\n",
       "      <td>-0.062455</td>\n",
       "      <td>0.133064</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V21</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.732964</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228406</td>\n",
       "      <td>-0.029479</td>\n",
       "      <td>0.186354</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V22</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.725492</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542305</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.528555</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V23</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.624701</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161865</td>\n",
       "      <td>-0.011210</td>\n",
       "      <td>0.147633</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V24</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.605606</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354566</td>\n",
       "      <td>0.040961</td>\n",
       "      <td>0.439368</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V25</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317129</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V26</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.482242</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326991</td>\n",
       "      <td>-0.052175</td>\n",
       "      <td>0.240957</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V27</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.403513</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070824</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091067</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>V28</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.330230</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052950</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>0.078279</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Amount</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>88.361065</td>\n",
       "      <td>250.169582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Class</td>\n",
       "      <td>284337.0</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284337.0  94797.597397  47472.343458   29.000000  54208.000000   \n",
       "V1      284337.0     -0.000134      1.958362  -56.407510     -0.920439   \n",
       "V2      284337.0     -0.000195      1.651311  -72.715728     -0.598655   \n",
       "V3      284337.0      0.000499      1.514942  -48.325589     -0.889801   \n",
       "V4      284337.0     -0.000128      1.415447   -5.600607     -0.848668   \n",
       "V5      284337.0     -0.000112      1.380077 -113.743307     -0.691700   \n",
       "V6      284337.0      0.000077      1.332412  -26.160506     -0.768212   \n",
       "V7      284337.0      0.000035      1.235462  -43.557242     -0.554147   \n",
       "V8      284337.0      0.000097      1.192689  -73.216718     -0.208555   \n",
       "V9      284337.0      0.000320      1.098555  -13.434066     -0.642983   \n",
       "V10     284337.0     -0.000006      1.087753  -24.588262     -0.535584   \n",
       "V11     284337.0      0.000022      1.020488   -4.797473     -0.762356   \n",
       "V12     284337.0     -0.000130      0.998749  -18.683715     -0.405776   \n",
       "V13     284337.0      0.000195      0.995459   -5.791881     -0.648413   \n",
       "V14     284337.0      0.000276      0.957689  -19.214325     -0.425512   \n",
       "V15     284337.0      0.000012      0.915325   -4.498945     -0.582896   \n",
       "V16     284337.0      0.000240      0.875806  -14.129855     -0.467948   \n",
       "V17     284337.0      0.000232      0.848488  -25.162799     -0.483652   \n",
       "V18     284337.0      0.000151      0.838066   -9.498746     -0.498800   \n",
       "V19     284337.0      0.000076      0.813940   -7.213527     -0.456226   \n",
       "V20     284337.0      0.000019      0.771187  -54.497720     -0.211693   \n",
       "V21     284337.0     -0.000086      0.732964  -34.830382     -0.228406   \n",
       "V22     284337.0      0.000011      0.725492  -10.933144     -0.542305   \n",
       "V23     284337.0     -0.000035      0.624701  -44.807735     -0.161865   \n",
       "V24     284337.0     -0.000045      0.605606   -2.836627     -0.354566   \n",
       "V25     284337.0      0.000053      0.521277  -10.295397     -0.317129   \n",
       "V26     284337.0     -0.000010      0.482242   -2.604551     -0.326991   \n",
       "V27     284337.0      0.000023      0.403513  -22.565679     -0.070824   \n",
       "V28     284337.0      0.000018      0.330230  -15.430084     -0.052950   \n",
       "Amount  284337.0     88.361065    250.169582    0.000000      5.600000   \n",
       "Class   284337.0      0.001713      0.041350    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84666.000000  139293.000000  172792.000000  \n",
       "V1          0.018109       1.315499       2.454930  \n",
       "V2          0.065416       0.803687      22.057729  \n",
       "V3          0.179993       1.027518       9.382558  \n",
       "V4         -0.019838       0.743303      16.875344  \n",
       "V5         -0.054592       0.611678      34.801666  \n",
       "V6         -0.274148       0.398659      73.301626  \n",
       "V7          0.040032       0.570272     120.589494  \n",
       "V8          0.022368       0.327404      20.007208  \n",
       "V9         -0.051224       0.597469      15.594995  \n",
       "V10        -0.092985       0.453821      23.745136  \n",
       "V11        -0.032711       0.739596      12.018913  \n",
       "V12         0.139945       0.618100       7.848392  \n",
       "V13        -0.013392       0.662790       7.126883  \n",
       "V14         0.050674       0.493281      10.526766  \n",
       "V15         0.048072       0.648836       8.877742  \n",
       "V16         0.066554       0.523392      17.315112  \n",
       "V17        -0.065570       0.399762       9.253526  \n",
       "V18        -0.003553       0.500900       5.041069  \n",
       "V19         0.003768       0.458972       5.591971  \n",
       "V20        -0.062455       0.133064      39.420904  \n",
       "V21        -0.029479       0.186354      27.202839  \n",
       "V22         0.006675       0.528555      10.503090  \n",
       "V23        -0.011210       0.147633      22.528412  \n",
       "V24         0.040961       0.439368       4.584549  \n",
       "V25         0.016657       0.350796       7.519589  \n",
       "V26        -0.052175       0.240957       3.517346  \n",
       "V27         0.001342       0.091067      31.612198  \n",
       "V28         0.011258       0.078279      33.847808  \n",
       "Amount     22.000000      77.200000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Label which we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Labels Contain 2 Classes = Binary Classification\n",
    "\n",
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of these transactions are fraudulent where the Class is 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Transactions: 284337\n",
      "Non-Fraud: 283850\n",
      "Fraud: 487\n",
      "Fraud Percentage: 0.17 %\n"
     ]
    }
   ],
   "source": [
    "class_count = df['Class'].value_counts()\n",
    "\n",
    "print('Number of Transactions:', class_count[1] + class_count[0])\n",
    "print('Non-Fraud:', class_count[0])\n",
    "print('Fraud:', class_count[1])\n",
    "print('Fraud Percentage:', round(class_count[1] / (class_count[1] + class_count[0])*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1948485d320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count.plot(color=['r'], \n",
    "kind='bar', title='Distribution of Non Fraud & Fraud Txns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning on Fraud Detection is a type of Anomaly Detection as the labels are highly imbalanced because fraudulent transactions are minor representation among all credit card transactions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In most dataset, Amount is commonly found as not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19484a0e860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Amount'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Apply a power transform featurewise to make data more Gaussian-like = Normally Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PowerTransformer function from the scikit package into this Jupyter notebook\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "# Instantiate PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PowerTransformer(copy=True, method='yeo-johnson', standardize=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the transform on the data\n",
    "\n",
    "pt.fit(df[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the power transform to the data\n",
    "\n",
    "df['Log Amount'] = pt.transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot to compare before and after the transformation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[['Amount', 'Log Amount']].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Amount Column as we now have the normally distributed Log Amount column\n",
    "df = df.drop(['Amount'], axis = 1)\n",
    "\n",
    "df = df.drop(['Time'], axis = 1)\n",
    "\n",
    "\n",
    "# Set TXNid as the index of the dataframe\n",
    "df = df.set_index('TXNid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>Log Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXNid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TXNA0000001</td>\n",
       "      <td>1.110880</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.517144</td>\n",
       "      <td>1.325407</td>\n",
       "      <td>-0.191573</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>0.117620</td>\n",
       "      <td>0.017665</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037709</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>-0.048198</td>\n",
       "      <td>0.232115</td>\n",
       "      <td>0.606201</td>\n",
       "      <td>-0.342097</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.665973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000002</td>\n",
       "      <td>1.249055</td>\n",
       "      <td>-0.624727</td>\n",
       "      <td>-0.710589</td>\n",
       "      <td>-0.991600</td>\n",
       "      <td>1.429973</td>\n",
       "      <td>3.692977</td>\n",
       "      <td>-1.090209</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.850149</td>\n",
       "      <td>-0.307081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006293</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>-0.129463</td>\n",
       "      <td>1.112970</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>1.196549</td>\n",
       "      <td>-0.048220</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000003</td>\n",
       "      <td>-2.008872</td>\n",
       "      <td>2.198527</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>1.159432</td>\n",
       "      <td>-0.815174</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>-0.617108</td>\n",
       "      <td>1.530817</td>\n",
       "      <td>-0.586832</td>\n",
       "      <td>0.129876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.294983</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>-0.236141</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.192230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000004</td>\n",
       "      <td>-0.607877</td>\n",
       "      <td>1.031345</td>\n",
       "      <td>1.740450</td>\n",
       "      <td>1.232106</td>\n",
       "      <td>0.418592</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.850893</td>\n",
       "      <td>-0.176267</td>\n",
       "      <td>-0.243501</td>\n",
       "      <td>0.148455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087329</td>\n",
       "      <td>0.258315</td>\n",
       "      <td>-0.264775</td>\n",
       "      <td>0.118282</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-0.217041</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>-0.033041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.202489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000005</td>\n",
       "      <td>-0.935732</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>2.746261</td>\n",
       "      <td>-1.077965</td>\n",
       "      <td>-0.305594</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>-0.296178</td>\n",
       "      <td>0.402776</td>\n",
       "      <td>-0.040472</td>\n",
       "      <td>-0.852046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>1.064864</td>\n",
       "      <td>-0.158325</td>\n",
       "      <td>0.295505</td>\n",
       "      <td>-0.259370</td>\n",
       "      <td>0.754195</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.093948</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.480996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284333</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.619742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284334</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "      <td>0.096129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284335</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "      <td>0.675434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284336</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.427436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284337</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "      <td>1.323106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284337 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    V1         V2        V3        V4        V5        V6  \\\n",
       "TXNid                                                                       \n",
       "TXNA0000001   1.110880   0.168717  0.517144  1.325407 -0.191573  0.019504   \n",
       "TXNA0000002   1.249055  -0.624727 -0.710589 -0.991600  1.429973  3.692977   \n",
       "TXNA0000003  -2.008872   2.198527  0.144242  1.159432 -0.815174  0.182288   \n",
       "TXNA0000004  -0.607877   1.031345  1.740450  1.232106  0.418592  0.119168   \n",
       "TXNA0000005  -0.935732   0.170416  2.746261 -1.077965 -0.305594  0.011577   \n",
       "...                ...        ...       ...       ...       ...       ...   \n",
       "TXNA0284333 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "TXNA0284334  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "TXNA0284335   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "TXNA0284336  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "TXNA0284337  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "                   V7        V8        V9       V10  ...       V21       V22  \\\n",
       "TXNid                                                ...                       \n",
       "TXNA0000001 -0.031849  0.117620  0.017665  0.044865  ... -0.037709  0.095701   \n",
       "TXNA0000002 -1.090209  0.967291  0.850149 -0.307081  ... -0.006293  0.009200   \n",
       "TXNA0000003 -0.617108  1.530817 -0.586832  0.129876  ...  0.094917  0.294983   \n",
       "TXNA0000004  0.850893 -0.176267 -0.243501  0.148455  ... -0.087329  0.258315   \n",
       "TXNA0000005 -0.296178  0.402776 -0.040472 -0.852046  ...  0.401212  1.064864   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "TXNA0284333 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "TXNA0284334  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "TXNA0284335 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "TXNA0284336 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "TXNA0284337  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "                  V23       V24       V25       V26       V27       V28  \\\n",
       "TXNid                                                                     \n",
       "TXNA0000001 -0.048198  0.232115  0.606201 -0.342097  0.036770  0.007480   \n",
       "TXNA0000002 -0.129463  1.112970  0.500382  1.196549 -0.048220  0.005094   \n",
       "TXNA0000003  0.011081  0.015249  0.034211 -0.236141  0.128291  0.117986   \n",
       "TXNA0000004 -0.264775  0.118282  0.173508 -0.217041  0.094312 -0.033041   \n",
       "TXNA0000005 -0.158325  0.295505 -0.259370  0.754195  0.046664  0.093948   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "TXNA0284333  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "TXNA0284334  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "TXNA0284335 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "TXNA0284336 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "TXNA0284337  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "             Class  Log Amount  \n",
       "TXNid                           \n",
       "TXNA0000001      0   -0.665973  \n",
       "TXNA0000002      0    0.204460  \n",
       "TXNA0000003      0   -1.192230  \n",
       "TXNA0000004      0   -0.202489  \n",
       "TXNA0000005      0   -0.480996  \n",
       "...            ...         ...  \n",
       "TXNA0284333      0   -1.619742  \n",
       "TXNA0284334      0    0.096129  \n",
       "TXNA0284335      0    0.675434  \n",
       "TXNA0284336      0   -0.427436  \n",
       "TXNA0284337      0    1.323106  \n",
       "\n",
       "[284337 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. iloc is used for data selection operation.\n",
    "\n",
    "\n",
    "2. The colon (:) before the comma refers to the rows, and with the colon, we are taking all rows in the dataset.\n",
    "\n",
    "\n",
    "3. Here, we have selected all rows of all columns except the 'Class' column from the df dataset into X dataset. Now, X contains our features = inputs we need to train a model.\n",
    "\n",
    "\n",
    "4. Again with the y, we included all the rows under the 'Class' column into y. y contains our labels = outputs we want to infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[: , df.columns != 'Class']\n",
    "y = df.iloc[: , df.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Log Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXNid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TXNA0000001</td>\n",
       "      <td>1.110880</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.517144</td>\n",
       "      <td>1.325407</td>\n",
       "      <td>-0.191573</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>-0.031849</td>\n",
       "      <td>0.117620</td>\n",
       "      <td>0.017665</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190120</td>\n",
       "      <td>-0.037709</td>\n",
       "      <td>0.095701</td>\n",
       "      <td>-0.048198</td>\n",
       "      <td>0.232115</td>\n",
       "      <td>0.606201</td>\n",
       "      <td>-0.342097</td>\n",
       "      <td>0.036770</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>-0.665973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000002</td>\n",
       "      <td>1.249055</td>\n",
       "      <td>-0.624727</td>\n",
       "      <td>-0.710589</td>\n",
       "      <td>-0.991600</td>\n",
       "      <td>1.429973</td>\n",
       "      <td>3.692977</td>\n",
       "      <td>-1.090209</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.850149</td>\n",
       "      <td>-0.307081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097853</td>\n",
       "      <td>-0.006293</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>-0.129463</td>\n",
       "      <td>1.112970</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>1.196549</td>\n",
       "      <td>-0.048220</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.204460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000003</td>\n",
       "      <td>-2.008872</td>\n",
       "      <td>2.198527</td>\n",
       "      <td>0.144242</td>\n",
       "      <td>1.159432</td>\n",
       "      <td>-0.815174</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>-0.617108</td>\n",
       "      <td>1.530817</td>\n",
       "      <td>-0.586832</td>\n",
       "      <td>0.129876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028740</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.294983</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>-0.236141</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>-1.192230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000004</td>\n",
       "      <td>-0.607877</td>\n",
       "      <td>1.031345</td>\n",
       "      <td>1.740450</td>\n",
       "      <td>1.232106</td>\n",
       "      <td>0.418592</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.850893</td>\n",
       "      <td>-0.176267</td>\n",
       "      <td>-0.243501</td>\n",
       "      <td>0.148455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254325</td>\n",
       "      <td>-0.087329</td>\n",
       "      <td>0.258315</td>\n",
       "      <td>-0.264775</td>\n",
       "      <td>0.118282</td>\n",
       "      <td>0.173508</td>\n",
       "      <td>-0.217041</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>-0.033041</td>\n",
       "      <td>-0.202489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000005</td>\n",
       "      <td>-0.935732</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>2.746261</td>\n",
       "      <td>-1.077965</td>\n",
       "      <td>-0.305594</td>\n",
       "      <td>0.011577</td>\n",
       "      <td>-0.296178</td>\n",
       "      <td>0.402776</td>\n",
       "      <td>-0.040472</td>\n",
       "      <td>-0.852046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005419</td>\n",
       "      <td>0.401212</td>\n",
       "      <td>1.064864</td>\n",
       "      <td>-0.158325</td>\n",
       "      <td>0.295505</td>\n",
       "      <td>-0.259370</td>\n",
       "      <td>0.754195</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.093948</td>\n",
       "      <td>-0.480996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284333</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>-1.619742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284334</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0.096129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284335</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0.675434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284336</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>-0.427436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284337</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>1.323106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284337 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    V1         V2        V3        V4        V5        V6  \\\n",
       "TXNid                                                                       \n",
       "TXNA0000001   1.110880   0.168717  0.517144  1.325407 -0.191573  0.019504   \n",
       "TXNA0000002   1.249055  -0.624727 -0.710589 -0.991600  1.429973  3.692977   \n",
       "TXNA0000003  -2.008872   2.198527  0.144242  1.159432 -0.815174  0.182288   \n",
       "TXNA0000004  -0.607877   1.031345  1.740450  1.232106  0.418592  0.119168   \n",
       "TXNA0000005  -0.935732   0.170416  2.746261 -1.077965 -0.305594  0.011577   \n",
       "...                ...        ...       ...       ...       ...       ...   \n",
       "TXNA0284333 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "TXNA0284334  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "TXNA0284335   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "TXNA0284336  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "TXNA0284337  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "                   V7        V8        V9       V10  ...       V20       V21  \\\n",
       "TXNid                                                ...                       \n",
       "TXNA0000001 -0.031849  0.117620  0.017665  0.044865  ... -0.190120 -0.037709   \n",
       "TXNA0000002 -1.090209  0.967291  0.850149 -0.307081  ...  0.097853 -0.006293   \n",
       "TXNA0000003 -0.617108  1.530817 -0.586832  0.129876  ...  0.028740  0.094917   \n",
       "TXNA0000004  0.850893 -0.176267 -0.243501  0.148455  ...  0.254325 -0.087329   \n",
       "TXNA0000005 -0.296178  0.402776 -0.040472 -0.852046  ... -0.005419  0.401212   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "TXNA0284333 -4.918215  7.305334  1.914428  4.356170  ...  1.475829  0.213454   \n",
       "TXNA0284334  0.024330  0.294869  0.584800 -0.975926  ...  0.059616  0.214205   \n",
       "TXNA0284335 -0.296827  0.708417  0.432454 -0.484782  ...  0.001396  0.232045   \n",
       "TXNA0284336 -0.686180  0.679145  0.392087 -0.399126  ...  0.127434  0.265245   \n",
       "TXNA0284337  1.577006 -0.414650  0.486180 -0.915427  ...  0.382948  0.261057   \n",
       "\n",
       "                  V22       V23       V24       V25       V26       V27  \\\n",
       "TXNid                                                                     \n",
       "TXNA0000001  0.095701 -0.048198  0.232115  0.606201 -0.342097  0.036770   \n",
       "TXNA0000002  0.009200 -0.129463  1.112970  0.500382  1.196549 -0.048220   \n",
       "TXNA0000003  0.294983  0.011081  0.015249  0.034211 -0.236141  0.128291   \n",
       "TXNA0000004  0.258315 -0.264775  0.118282  0.173508 -0.217041  0.094312   \n",
       "TXNA0000005  1.064864 -0.158325  0.295505 -0.259370  0.754195  0.046664   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "TXNA0284333  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651   \n",
       "TXNA0284334  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472   \n",
       "TXNA0284335  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455   \n",
       "TXNA0284336  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821   \n",
       "TXNA0284337  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415   \n",
       "\n",
       "                  V28  Log Amount  \n",
       "TXNid                              \n",
       "TXNA0000001  0.007480   -0.665973  \n",
       "TXNA0000002  0.005094    0.204460  \n",
       "TXNA0000003  0.117986   -1.192230  \n",
       "TXNA0000004 -0.033041   -0.202489  \n",
       "TXNA0000005  0.093948   -0.480996  \n",
       "...               ...         ...  \n",
       "TXNA0284333  0.823731   -1.619742  \n",
       "TXNA0284334 -0.053527    0.096129  \n",
       "TXNA0284335 -0.026561    0.675434  \n",
       "TXNA0284336  0.104533   -0.427436  \n",
       "TXNA0284337  0.013649    1.323106  \n",
       "\n",
       "[284337 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X    # X contains all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXNid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>TXNA0000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0000005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TXNA0284337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284337 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Class\n",
       "TXNid             \n",
       "TXNA0000001      0\n",
       "TXNA0000002      0\n",
       "TXNA0000003      0\n",
       "TXNA0000004      0\n",
       "TXNA0000005      0\n",
       "...            ...\n",
       "TXNA0284333      0\n",
       "TXNA0284334      0\n",
       "TXNA0284335      0\n",
       "TXNA0284336      0\n",
       "TXNA0284337      0\n",
       "\n",
       "[284337 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y    # y contains all the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import the train_test_split function from the scikit package into this Jupyter notebook.\n",
    "\n",
    "What it does:\n",
    "1. Split our dataset into a training set and a test set.\n",
    "\n",
    "2. Telling scikit-learn that size of the training set will be 80%\n",
    "\n",
    "3. Setting random_state a fixed value will guarantee that same sequence of random numbers are generated each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=8606)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the Architecture of a Deep Neural Network in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep neural networks** contain multiple non-linear hidden layers and this makes them the expressive models that can learn very complicated relationships between their inputs and outputs\n",
    "\n",
    "\n",
    "In a neural network, numeric data points, called inputs, are fed into the neurons in the input layer. Each neuron has a weight, and multiplying the input number with the weight gives the output of the neuron, which is transferred to the next layer.\n",
    "\n",
    "\n",
    "**1. Keras** = A high-level neural networks API written in Python. The Keras API is the official frontend of TensorFlow.\n",
    "\n",
    "**2. Sequential** = A linear stack of layers which we can use it to build a Multilayer Perceptron.\n",
    "\n",
    "**3. Dense** = Implement to build the densely-connected neural network layer.\n",
    "\n",
    "**4. Dropout** = A regularization layer for reducing overfitting by randomly drop units from neural network during model training. Dropout usually improve generalization performance on all data sets compared to neural networks that did not use dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Activation** = Activation functions are mathematical equations attached to each neuron in the network that determine the output of a neural network.\n",
    "\n",
    "•\tAn activation functions allows the model to capture nonlinearities in the training dataset.\n",
    "\n",
    "•\tIt applies to the value coming into a node, then transform it into the value stored in that node as the node output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a Deep Neural Network with Sequential\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(16, input_dim =29, activation='relu'))\n",
    "model1.add(Dense(24, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(20, activation='relu'))\n",
    "model1.add(Dense(24, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st Layer** = 16 Neurons, 29 Input Features, relu is the activation\n",
    "\n",
    "**2nd Layer** = 24 Neurons, relu is the activation\n",
    "\n",
    "**3rd Layer** = Dropout at 0.5 = probability of 0.5 for retaining the output of each node in this hidden layer\n",
    "\n",
    "**4th Layer** = 20 Neurons, relu is the activation\n",
    "\n",
    "**5th Layer** = 24 Neurons, relu is the activation\n",
    "\n",
    "**6th Layer** = 1 Neurons, sigmoid is the activation\n",
    "\n",
    "\n",
    "**Rectified Linear Activation Function** or ReLU in short, is commonly used as activation function by both the industries and researchers.\n",
    "\n",
    "1. When an input into a node is negative, output = 0, so the slope is 0\n",
    "2. When an input into a node is positive, output = the input value, so the slope is 1 \n",
    "\n",
    "\n",
    "**Sigmoid** is a logistic regression function with the output values bond between 0 and 1, hence it is the right function here for the output layer which we want to produce binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the model by calling the function model.compile and then fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer** = Optimizers are algorithms or methods used to change the attributes of a neural network such as weights and learning rate in order to reduce the losses or errors.\n",
    "\n",
    "**Loss** = Also known as error function, is used to measure how accurate our algorithm is doing. The loss function for outputs producing 0 or 1 is called binary crossentropy.\n",
    "\n",
    "**Metrics** = Accuracy is used when we want to track accuracy on top of the loss function.\n",
    "\n",
    "**Batch Size** = Number of training examples per batch.\n",
    "\n",
    "**Epoch** = The full training dataset forward propogates and then backpropogates for one cycle.\n",
    "\n",
    "*Example: We have 2000 rows of training set, when set batch size = 200, then after 10 iterations, it completed 1 epoch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chunpin\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\chunpin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "227469/227469 [==============================] - 2s 10us/step - loss: 0.0355 - accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "227469/227469 [==============================] - 2s 7us/step - loss: 0.0026 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1949a52f7f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# X_train is the first argument because this is our features for training, \n",
    "# and y_train is the second argument as it is our label for training\n",
    "\n",
    "model1.fit(X_train, y_train , batch_size = 200, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Credit** to *machinelearningknowledge.ai* for a great animation of the forward propogation and backpropagation of neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model's Error and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56868/56868 [==============================] - 1s 14us/step\n",
      "[0.0039004114842793995, 0.9992086887359619]\n"
     ]
    }
   ],
   "source": [
    "loss_and_accuracy = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print(loss_and_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will use the model trained with X_train dataset, to predict the class (a.k.a. label or y) of the X_test dataset. \n",
    "\n",
    "### And, we name it as y_hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1081181e-05],\n",
       "       [5.0663948e-07],\n",
       "       [2.7835369e-05],\n",
       "       ...,\n",
       "       [9.8529250e-05],\n",
       "       [1.1495957e-05],\n",
       "       [8.6878004e-05]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert the y_test to pandas' dataframe\n",
    "\n",
    "y_hat = pd.DataFrame(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56867</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56868 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      0.0\n",
       "1      0.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "...    ...\n",
       "56863  0.0\n",
       "56864  0.0\n",
       "56865  0.0\n",
       "56866  0.0\n",
       "56867  0.0\n",
       "\n",
       "[56868 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_test = Actual Labels\n",
    "### y_hat = Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_hat.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TN** **FP**\n",
    "\n",
    "**FN** **TP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56743    23]\n",
      " [   22    80]]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FP** = Actual is 0 or Non-Fraud **BUT** Predicted as 1 or Fraud\n",
    "\n",
    "**FN** = Actual is 1 or Fraud **BUT** Predicted as 0 or Non-Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a Confusion Matrix with the matplotlib Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[56743    23]\n",
      " [   22    80]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEYCAYAAADRWAT6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xm8VVXdx/HPF64DJCipKOKYojiUDAoOaY6IpWHOSGpKkak5lJVDhUOWZk6UVvo44JRDpuIE8qD2pKkJSjgLOSRgKmMMogy/54+97vWI95x77j33cO45fN+99uuevfbae//OvfZj7b32WlsRgZmZNa5dpQMwM2vLnCTNzApwkjQzK8BJ0sysACdJM7MCnCTNzApwkqwxkjpIul/SXEl3lXCcIZIeac3YKkXSbpJeq3QcVp3k5yQrQ9JRwA+AnsA8YCJwYUQ8UeJxjwa+D+wSEUtKDrSNkxRAj4iYUulYrDa5JVkBkn4AXAH8ElgP2Bi4GhjUCoffBHh9ZUiQxZBUV+kYrMpFhJcVuABrAvOBwwrUWY0siU5PyxXAamnbHsBU4IfA+8C7wHFp23nAx8DidI6hwLnALTnH3hQIoC6tfwt4g6w1+yYwJKf8iZz9dgGeBeamn7vkbHscuAB4Mh3nEWCdPN+tPv4f58R/EPBV4HVgFnB2Tv1+wFPAnFT3d8Cqadv/pe+yIH3fI3KO/xPgP8DN9WVpn83TOfqk9Q2AGcAelf5vw0vbXNySXPF2BlYH7ilQ5xxgJ6AXsD1Zovhpzvb1yZJtd7JEeJWkLhExnKx1ekdErBER1xUKRNLngBHA/hHRiSwRTmyk3ueBB1PdtYHLgAclrZ1T7SjgOKArsCpwRoFTr0/2O+gO/By4Fvgm0BfYDfi5pC+kukuB04F1yH53ewMnAkTE7qnO9un73pFz/M+TtaqH5Z44Iv5FlkBvldQRuAG4MSIeLxCvrcScJFe8tYEZUfhyeAhwfkS8HxEfkLUQj87ZvjhtXxwRD5G1orZqYTzLgO0kdYiIdyPipUbqfA2YHBE3R8SSiPgT8CpwYE6dGyLi9Yj4ELiTLMHns5js/uti4HayBHhlRMxL538J+BJAREyIiKfTed8C/gh8pYjvNDwiPkrxfEpEXAtMBp4BupH9o2TWKCfJFW8msE4T98o2AN7OWX87lTUcY7kkuxBYo7mBRMQCskvUE4B3JT0oqWcR8dTH1D1n/T/NiGdmRCxNn+uT2Hs52z+s31/SlpIekPQfSf8laymvU+DYAB9ExKIm6lwLbAf8NiI+aqKurcScJFe8p4BFZPfh8plOdqlYb+NU1hILgI456+vnboyIMRGxL1mL6lWy5NFUPPUxTWthTM3xe7K4ekREZ+BsQE3sU/CRDUlrkN3nvQ44N91OMGuUk+QKFhFzye7DXSXpIEkdJa0iaX9Jv07V/gT8VNK6ktZJ9W9p4SknArtL2ljSmsBZ9RskrSfp6+ne5Edkl+1LGznGQ8CWko6SVCfpCGAb4IEWxtQcnYD/AvNTK/d7y21/D/jCZ/Yq7EpgQkR8m+xe6x9KjtJqlpNkBUTEZWTPSP4U+AB4BzgZuDdV+QUwHpgEvAA8l8pacq6xwB3pWBP4dGJrR9ZLPp2sx/crpE6R5Y4xEzgg1Z1J1jN9QETMaElMzXQGWafQPLJW7h3LbT8XGClpjqTDmzqYpEHAQLJbDJD9HfpIGtJqEVtN8cPkZmYFuCVpZlaAk6SZWQFOkmZmBThJmpkV0KYG/6uuQ2jVTpUOw5qh99YbVzoEa4a3336LGTNmNPWcabO077xJxJLPDGxqVHz4wZiIGNia5y+3tpUkV+3Eals1+RSHtSFPPvO7SodgzbBr/x1a/Zix5MOi/3+7aOJVTY2WanPaVJI0s2okUO3euXOSNLPSCGjXvtJRlI2TpJmVTq16m7NNcZI0sxL5ctvMrDC3JM3M8hBuSZqZ5Se3JM3MCnLvtplZPu64MTPLT/hy28ysILckzczy8eW2mVlh7Xy5bWbWOI/dNjMrxJfbZmaFuXfbzKwAtyTNzPKQhyWamRXmjhszs3zccWNmVlgNX27Xbvo3sxWjfj7JYpZiDie9JekFSRMljU9ln5c0VtLk9LNLKpekEZKmSJokqU/OcY5N9SdLOjanvG86/pS0b8EM7yRpZiVSqybJZM+I6BUR9e/APRMYFxE9gHFpHWB/oEdahgG/hyypAsOB/kA/YHh9Yk11huXsV/A94E6SZla6+h7uppaWGwSMTJ9HAgfllN8UmaeBtSR1A/YDxkbErIiYDYwFBqZtnSPiqYgI4KacYzXKSdLMSteufXELrCNpfM4yrJGjBfCIpAk529eLiHcB0s+uqbw78E7OvlNTWaHyqY2U5+WOGzMrjZrVuz0j5xI6n10jYrqkrsBYSa8WOnsjZdGC8rzckjSz0rXi5XZETE8/3wfuIbun+F66VCb9fD9VnwpslLP7hsD0Jso3bKQ8LydJMyuZpKKWIo7zOUmd6j8DA4AXgVFAfQ/1scB96fMo4JjUy70TMDddjo8BBkjqkjpsBgBj0rZ5knZKvdrH5ByrUb7cNrOSZG9vaLXnJNcD7knHqwNui4jRkp4F7pQ0FPg3cFiq/xDwVWAKsBA4DiAiZkm6AHg21Ts/Imalz98DbgQ6AA+nJS8nSTMrjWj8Tl8LRMQbwPaNlM8E9m6kPICT8hzreuD6RsrHA9sVG5OTpJmVSLRrV7t37pwkzaxkrXi53eY4SZpZyZwkzczyacV7km2Rk6SZlUQU93hPtXKSNLOSuePGzKwAtyTNzPLxPUkzs8LckjQzy8MdN2ZmTXCSNDPLR6B2TpJmZnm5JWlmVoCTpJlZHu64MTNrSu3mSCfJ5nj1wfOYt+Ajli5bxpKly/jykF8D8L0jv8IJR+zOkqXLGP23Fznnyvs4cv8dOO3YfRr2/WKPDdh58MVMen1aQ9ldV3yXzbqvzQ6H/RKAn5/4NQ74ypdYFsEHs+YxbPgtvPvB3BX7JVcy77zzDt8+7hjee+8/tGvXjuOHDuPkU07lvOE/44FR99GuXTvW7dqVa667kQ022KDS4bZN8uW25Rg47EpmzlnQsL77Dj04YI8vsuPhv+LjxUtYt8saANz+8Hhuf3g8ANtusQF3XT7sUwly0F7bs2DhR5869uUjx3H+1Q8CcOLgr3DWsP055cLby/2VVmp1dXVc9OtL6d2nD/PmzWOX/n3Ze599Of2HP2L4eRcAcNVvR/CrX5zPb6/+Q4Wjbbtqeex27X6zFWTYYbvxmxvG8vHiJQB8MHv+Z+ocPrAvd46e0LD+uQ6rcso39+Ki/xn9qXrzFixq+Nyxw2pkM9NbOXXr1o3effoA0KlTJ3r23Jrp06fRuXPnhjoLFy6o6ZZSq1CRSxVyS7IZIoL7rz6ZiOC6u5/k+r88yRabdGXX3ptz3kkHsujjxZx12T1MePnfn9rv0AF9OOz0axrWh594AFfePI6FH378mXOce9KBDDmgH3Pnf8jAYSPK/p3sE2+/9RYTJz7Pjv36AzD8Z+dw6y03seaaazJ67GMVjq5tq+V/RMrakpQ0UNJrkqZIOrOc51oR9jrucnY56mIOOvlqvnvEbuzaZ3Pq2rejS+eO7H7Mbzj78nu55dfHf2qfHbfbhIWLFvPyv94F4EtbducLG63LqMcmNXqOc6+6nx77/4zbHx7PCUfsXvbvZJn58+cz+PBDuOTSKxpakeddcCFT3nyHIwcP4Q9X/67CEbZdxb5OtloTadmSpKT2wFXA/sA2wGBJ25TrfCtCfSfKB7PnM+rRSey47aZMe28O9477JwDjX3qbZcuCddJ9SYDD9uvLnaPHN6z3334z+myzMa8+eB6P3nA6PTbpyphrT/3Mue58+FkO2rtXmb+RASxevJjBhx/CEYOHcNA3Dv7M9sOPPIp777m7ApFVDyfJlukHTImINyLiY+B2YFAZz1dWHVdflTU6rtbweZ+de/LSv6Zz/+OT2KPflgBssXFXVl2ljhnpvqQkDt63N3eN+eR+5LV3PcEXBpxDz68NZ6/jLmfy2++z33euBGDzjddtqPe1r3yJ1996b0V9vZVWRHDCd4ayVc+tOfX0HzSUT5k8ueHzg/ePYsutelYivKpRy0mynPckuwPv5KxPBfovX0nSMGAYAKussfzmNqPr2p2447LvAFDXvj13PDyesX9/hVXq2vPHc4cw/q6z+XjxUr7985sb9vlyny2Y9t4c3po2s6hz/OKUQfTYpCvLlgX/fneWe7ZXgL8/+SS33Xoz2233Rfr3zVru5/3il9x4w3VMfv012qkdG2+yCSOucs92IbU8dlvl6kGVdBiwX0R8O60fDfSLiO/n26ddx66x2laHlyUeK4/Zz/peXTXZtf8OTJgwvlUz2mrr94gNhxTXyfjGZV+dEBE7tOb5y62cLcmpwEY56xsC08t4PjOrAAFVeiVdlHLek3wW6CFpM0mrAkcCo8p4PjOriNru3S5bSzIilkg6GRgDtAeuj4iXynU+M6ucKs1/RSnrw+QR8RDwUDnPYWYVJmhXwx03HpZoZiURWZIsZinqeFJ7Sc9LeiCtbybpGUmTJd2Rbt8habW0PiVt3zTnGGel8tck7ZdT3uwBLk6SZlYyqbilSKcCr+SsXwxcHhE9gNnA0FQ+FJgdEVsAl6d6pEErRwLbAgOBq1PibdEAFydJMytZa3XcSNoQ+BrwP2ldwF7An1OVkcBB6fOgtE7avneqPwi4PSI+iog3gSlkg1taNMDFSdLMSlNkK7LIluQVwI+BZWl9bWBORCxJ61PJBqpAzoCVtH1uqt/YQJbuBcoLcpI0s5Jkz0kW3ZJcR9L4nGVYw3GkA4D3I2LCcodfXjSxrbnlBXmqNDMrUfGdMsCMAiNudgW+LumrwOpAZ7KW5VqS6lJrMXdQSv2AlamS6oA1gVkUHsjS7AEubkmaWcla455kRJwVERtGxKZkHS+PRsQQ4DHg0FTtWOC+9HlUWidtfzSycdajgCNT7/dmQA/gH7RwgItbkmZWmub1XLfET4DbJf0CeB64LpVfB9wsaQpZC/JIgIh4SdKdwMvAEuCkiFgK0JIBLk6SZlaS+nuSrSkiHgceT5/fIOuZXr7OIuCwPPtfCFzYSHmzB7g4SZpZyTws0cysgGqdvKIYTpJmVpoaH7vtJGlmJan1+SSdJM2sRNU7V2QxnCTNrGQ1nCOdJM2sdG5JmpnlIXfcmJkV5pakmVkBNZwjnSTNrHQrZUtS0v0UmGstIr5elojMrLqUf4KLiirUkvzNCovCzKqWVtbnJCPir/WfJXUANo6I11ZIVGZWVdrXcO92k5PuSjoQmAiMTuu9JDU5UaWZrTxa+W2JbUoxM5OfSzaX2xyAiJgIbFq+kMysmmQJsHXeltgWFdO7vSQi5lbrFzSz8qvhq+2ikuSLko4C2kvqAZwC/L28YZlZNanlRlQxl9vfB7YFPgL+BPwXOK2cQZlZdanle5JNtiQjYiFwjqSLs9WYV/6wzKxaCGhfrRmwCMX0bu8o6QVgEvCCpH9K6lv+0MysKhTZaVOtl+TF3JO8DjgxIv4GIOnLwA3Al8oZmJlVjyrNf0UpJknOq0+QABHxhCRfcpsZkF1ut6vhLFlo7Haf9PEfkv5I1mkTwBGk9+GamcHK25K8dLn14Tmf8058YWYrl5V20t2I2HNFBmJm1WulvNzOJelrZM9Krl5fFhHnlysoM6sutZsii0iSkv4AdAT2BP4HOBT4R5njMrMqUq2P9xSjmBE3u0TEMcDsiDgP2BnYqLxhmVm1yHq3i1uqUTGX2x+mnwslbQDMBDYrX0hmVlWq+EHxYhTTknxA0lrAJcBzwFtkjwOZmQFZ73YxS1MkrS7pH2lk30uSzkvlm0l6RtJkSXdIWjWVr5bWp6Ttm+Yc66xU/pqk/XLKB6ayKZLObPK7NVUhIi6IiDkRcTewCdATeLDJb2tmK4VWvtz+CNgrIrYHegEDJe0EXAxcHhE9gNnA0FR/KNmtwC2Ay1M9JG0DHEnW4TwQuFpSe0ntgauA/YFtgMGpbl7FtCQbRMRHETEXuKs5+5lZbWutsduRmZ9WV0lLAHsBf07lI4GD0udBaZ20fW9lJxoE3J5y1pvAFLLJw/sBUyLijYj4GLg91c2rWUkyR+3egDCzZlORC7COpPE5y7DPHCtr8U0E3gfGAv8C5kTEklRlKtA9fe4OvAOQts8F1s4tX26ffOV5tfS92x5xY2ZAGnFTfMfNjIjYoVCFiFgK9Ep9IfcAWzdWrf70ebblK2+sYVgwn7Xkvdsiy9RmZkB5xm5HxBxJjwM7AWtJqkutxQ2B6anaVLJHEqdKqgPWBGbllNfL3SdfeaNa+t5tv5PbzBq01thtSesCi1OC7ADsQ9YZ8xjZQJbbgWOB+9Iuo9L6U2n7oxER6Y2ut0m6DNgA6EE2CEZAD0mbAdPIOneOKhRTUe/dNjPLR6g1x253A0amXuh2wJ0R8YCkl4HbJf0CeJ5snlvSz5slTSFrQR4JEBEvSboTeBlYApyULuORdDIwBmgPXB8RLxUKqKX3JM3MMq34/pqImAT0bqT8DbKe6eXLFwGH5TnWhcCFjZQ/BDxUbExtKkn23npjnnzmd5UOw8yaqZZH3LSpJGlm1amlzxJWg5b0bgMQEV8vS0RmVlXEytuSdA+2mRWlroabku7dNrOSSCtvSxIAST2AX5ENBs+dmfwLZYzLzKpItc4VWYxiGsk3AL8ne9ZoT+Am4OZyBmVm1UUqbqlGxSTJDhExDlBEvB0R55LNyGFm1vDe7WKWalTMI0CLJLUDJqcn1acBXcsblplVk/bVmf+KUkxL8jSyF4GdAvQFjiYbK2lmhopsRdZsSzIink0f5wPHlTccM6tGVZr/ilJM7/ZjNPJQeUT4vqSZAbXdu13MPckzcj6vDhxC1tNtZtbQcVOrirncnrBc0ZOS/KC5mTWo4RxZ1OX253NW25F13qxftojMrLoI2tdwlizmcnsCn7wzYgnwJp+8ztHMVnL1r5StVcUkya3TxJYNJK1WpnjMrArVcpIs5jnJvzdS9lRrB2Jm1au13rvdFhWaT3J9svfRdpDUm09e0diZ7OFyM7OV+nJ7P+BbZK9cvJRPkuR/gbPLG5aZVY0qnryiGIXmkxxJ9tayQyLi7hUYk5lVEQF1NdyULOaeZF9Ja9WvSOqSXutoZgZ4qrT9I2JO/UpEzAa+Wr6QzKy6iHZFLtWomEeA2ktaLSI+ApDUAfAjQGYG1L8IrNJRlE8xSfIWYJykG8geKj+ebHZyMzPQytu7DUBE/FrSJGAfsn80LoiIMWWPzMyqgoD2NZwli2lJEhGjgdEAknaVdFVEnFTWyMysaqzUswABSOoFDAaOIBu7/ZdyBmVm1aWGc2TBETdbAkeSJceZwB1kLwPbcwXFZmZVQBT3mEy1KvTdXgX2Bg6MiC9HxG+BpSsmLDOrGmq9sduSNpL0mKRXJL0k6dRU/nlJYyVNTj+7pHJJGiFpiqRJkvrkHOvYVH+ypGNzyvtKeiHtM0JNBFYoSR4C/Ad4TNK1kvaGKn3QyczKSkUuRVgC/DAitgZ2Ak6StA1wJjAuInoA49I6wP5Aj7QMA34PDfPgDgf6A/2A4fWJNdUZlrPfwEIB5U2SEXFPRBwB9AQeB04H1pP0e0kDivu+ZlbrRDbpbjFLUyLi3Yh4Ln2eB7xCNtHOIGBkqjYSOCh9HgTcFJmngbUkdSObe2JsRMxKA2DGAgPTts4R8VREBNnjjPXHalSTtxIiYkFE3BoRB5BNdjGRT7K4mVlZhiVK2hToDTwDrBcR70KWSIGuqVp34J2c3aamskLlUxspz6uo3u16ETEL+GNazMyAZs0VuY6k8Tnr10TENZ85orQGcDdwWkT8t8DxG9sQLSjPq1lJ0sxsec3s3Z4RETsUPJ60ClmCvDUi6h83fE9St4h4N10yv5/KpwIb5ey+ITA9le+xXPnjqXzDRurnVcs992a2grRi77aA64BXIuKynE2jgPoe6mOB+3LKj0m93DsBc9Pl+BhgQJq1rAswABiTts2TtFM61zE5x2qUW5JmVrJWfOxlV+Bo4AVJE1PZ2cBFwJ2ShgL/Bg5L2x4im5VsCrAQOA6yW4OSLgCeTfXOT7cLAb4H3Ah0AB5OS15OkmZWErXiK2Uj4gny59y9G6kfQKNDpCPieuD6RsrHA9sVG5OTpJmVrFpf8lUMJ0kzK1ntpkgnSTNrBTXckHSSNLPSZI8A1W6WdJI0s5K5JWlmlpc86a6ZWT6+3DYzK6SK36ldDCdJMyuZk6SZWQGq4cttT3DRit555x3222dPen1xa/psvy2/G3ElAGf95Edsv11Pduz9JQ4/9BvMmTOnwpFarhFXXE6f7belb6/tOOabg1m0aBFvvfkmu+3Sn+227sE3jzqCjz/+uNJhtlmtOeluW+Qk2Yrq6uq46NeXMvGFV/jrE0/zxz9cxSsvv8ze++zLhIkv8uzzk+jRY0suufhXlQ7VkmnTpnH1VSN48unxTJj4IkuXLuWuO27nnLN/wvdPPZ0XX5lMl7W6cOP111U61DatHJPuthVOkq2oW7du9O6TvYeoU6dO9Oy5NdOnT2OffQdQV5fd2ejXfyemTZ1a6DC2gi1ZsoQPP/ww+7lwIet368ZfH3uUgw85FIAhRx/L/aPurXCUbZuK/F81cpIsk7ffeouJE59nx379P1V+043Xs9/A/SsUlS2ve/funHb6GWz5hY3ZbKNudO68Jr379GXNtdZq+Iet+4YbMn36tApH2nYJaKfilmpUtiQp6XpJ70t6sVznaKvmz5/P4MMP4ZJLr6Bz584N5Rf/6kLa19Vx5FFDKhid5Zo9ezYP3H8fr0x+kzf+PZ0FCxfwyOjPTi9Yra2gFaPYdmR1/g7L2ZK8kSZe1ViLFi9ezODDD+GIwUM46BsHN5TfctNIHnrwAW686daanlaq2jw67n/ZdNPNWHfddVlllVU46KCDefqpvzN3zhyWLFkCwLSpU+m2wQYVjrQNK/J+ZLX+Z1+2JBkR/wfMarJiDYkITvjOULbquTWnnv6DhvJHxozm0t9czJ/vGUXHjh0rGKEtb6ONNuYf/3iahQsXEhE89ug4em69DbvvsSd/ufvPANx680gOOHBQhSNtu9y7XWaShkkaL2n8BzM+qHQ4Jfn7k09y260389fHHqV/317079uL0Q8/xOmnnsy8efM4YOC+9O/bi++feEKlQ7WkX//+fOPgQ9m5Xx926P1Fli1bxtDvDOPCX17MiCsuY9ueWzBz1ky+dfzQSofapqnIpRopm/28TAfP3pv7QEQUNVV63747xJPPjG+6opm1yK79d2DChPGtmq+2/mLvuOHex4qqu/MWXSY09bbEtsYjbsysZNXaKVMMJ0kzK1mV3m4sSjkfAfoT8BSwlaSp6VWQZlaDavmeZNlakhExuFzHNrO2Q/htiWZm+VXxM5DFcJI0s5LVcI50kjSzVlDDWdJJ0sxKVL3jsovhJGlmJamfBahWOUmaWemcJM3M8qvly+2KT3BhZtWvtaZKa2weWkmflzRW0uT0s0sql6QRkqZImiSpT84+x6b6kyUdm1PeV9ILaZ8RKuIBTydJMytZK464uZHPzkN7JjAuInoA49I6wP5Aj7QMA34PWVIFhgP9gX7A8PrEmuoMy9mvyTlvnSTNrDTFZsgismSeeWgHASPT55HAQTnlN0XmaWAtSd2A/YCxETErImYDY4GBaVvniHgqsunPbso5Vl6+J2lmJcl6t4u+J7mOpNz5EK+JiGua2Ge9iHgXICLeldQ1lXcH3smpNzWVFSqf2kh5QU6SZlayZnTbzGjF+SQbO220oLwgX26bWenKOw3Qe+lSmfTz/VQ+Fdgop96GwPQmyjdspLwgJ0kzK1mZ35Y4CqjvoT4WuC+n/JjUy70TMDddlo8BBkjqkjpsBgBj0rZ5knZKvdrH5BwrL19um1nJWmsWoDQP7R5k9y6nkvVSXwTcmeak/TdwWKr+EPBVYAqwEDgOICJmSboAeDbVOz8i6juDvkfWg94BeDgtBTlJmlnJWutR8gLz0O7dSN0ATspznOuB6xspHw8U9c6tek6SZlYST7prZlaIJ901MyushnOkk6SZtYIazpJOkmZWIk+6a2aWlyfdNTNripOkmVl+vtw2MyvAjwCZmRVQwznSSdLMSuSHyc3M8vOwRDOzJtRuinSSNLNWUMMNSSdJMyudHwEyMyukdnOkk6SZla6Gc6STpJmVRmrWK2WrjpOkmZWudnOkk6SZla6Gc6STpJmVroavtp0kzaxUnnTXzCyvbFhipaMoHydJMyuZk6SZWQG+3DYzy8dTpZmZ5Sf8CJCZWWE1nCWdJM2sZB6WaGZWQO2mSCdJM2sNNZwlnSTNrGS1/AiQIqLSMTSQ9AHwdqXjKIN1gBmVDsKapVb/ZptExLqteUBJo8l+X8WYEREDW/P85damkmStkjQ+InaodBxWPP/NrF67SgdgZtaWOUmamRXgJLliXFPpAKzZ/DczwPckzcwKckvSzKwAJ0kzswKcJM3MCnCSLBNJW0naWdIqktpXOh4rjv9Wtjx33JSBpIOBXwLT0jIeuDEi/lvRwCwvSVtGxOvpc/uIWFrpmKxtcEuylUlaBTgCGBoRewP3ARsBP5bUuaLBWaMkHQBMlHQbQEQsdYvS6jlJlkdnoEf6fA/wALAqcJRUwxPvVSFJnwNOBk4DPpZ0CzhR2iecJFtZRCwGLgMOlrRbRCwDngAmAl+uaHD2GRGxADgeuA04A1g9N1FWMjZrG5wky+NvwCPA0ZJ2j4ilEXEbsAGwfWVDs+VFxPSImB8RM4DvAh3qE6WkPpJ6VjZCqyTPJ1kGEbFI0q1AAGel/5N9BKwHvFvR4KygiJgp6bvAJZJeBdoDe1Y4LKsgJ8kyiYjZkq4FXiZrnSwCvhkR71U2MmtKRMyQNAnYH9g3IqZWOiarHD8CtAKkDoBI9yetjZPUBbgT+GFETKp0PFZZTpJmjZC0ekQsqnQcVnlOkmZmBbh328ysACdJM7MCnCTNzApwkjQzK8BJskpIWippoqQXJd0lqWMJx9pD0gPp89clnVmg7lqSTmxHvhJLAAAC4klEQVTBOc6VdEax5QWOM781zmvWUk6S1ePDiOgVEdsBHwMn5G5Uptl/z4gYFREXFaiyFtDsJGlWK5wkq9PfgC0kbSrpFUlXA88BG0kaIOkpSc+lFucaAJIGSnpV0hPAwfUHkvQtSb9Ln9eTdI+kf6ZlF+AiYPPUir0k1fuRpGclTZJ0Xs6xzpH0mqT/BbZqzheSdK+kCZJekjRsuW2Xpu8zTtK6qWxzSaPTPn/z+GorFyfJKiOpjmy43AupaCvgpojoDSwAfgrsExF9yCb7/YGk1YFrgQOB3YD18xx+BPDXiNge6AO8BJwJ/Cu1Yn8kaQDZNHD9gF5AX0m7S+oLHAn0JkvCOzbzqx0fEX2BHYBTJK2dyj8HPJe+z1+B4an8GuD7aZ8zgKubeT6zonjsdvXoIGli+vw34DqyWYXejoinU/lOwDbAk2naylWBp4CewJsRMRkgzXDzqdZashdwDDRMEzY3DdHLNSAtz6f1NciSZifgnohYmM4xqpnf7xRJ30ifN0rHnAksA+5I5bcAf0mt412Au3Km51ytmeczK4qTZPX4MCJ65RakBLEgtwgYGxGDl6vXi2xGotYg4FcR8cflznFaS88haQ9gH2DniFgo6XFg9TzVg+wKaM7yvw+zcvDldm15GthV0hYAkjpK2hJ4FdhM0uap3uA8+48Dvpf2bZ9eNzGPrJVYbwxwfM69zu6SugL/B3xDUgdJncgu7Yu1JjA7JcieZC3ieu2AQ9Pno4An0ruC3pR0WIpBkjxPp5WFk2QNiYgPgG8Bf0pTfT0N9EwTNQwDHkwdN2/nOcSpwJ6SXgAmANtGxEyyy/cXJV0SEY+QzeL9VKr3Z6BTRDxHdlk8Ebib7JZAPj+VNLV+AUYDdSnmC1Lc9RYA20qaQHY74PxUPgQYKumfZPdOBxX7ezJrDk9wYWZWgFuSZmYFOEmamRXgJGlmVoCTpJlZAU6SZmYFOEmamRXgJGlmVsD/A1dsCgaD7cS3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = model1.predict(X_test)\n",
    "y_actual = pd.DataFrame(y_test)\n",
    "cnf_matrix = confusion_matrix(y_actual, y_hat.round())\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negative needs to be further minimized to produce a reliable and accurate model for operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization: An Important Next Step to Enhance Classification Accuracy by Addressing Imbalance in Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE** or **Synthetic Minority Over-Sampling Technique** = An oversampling algorithm utilizes the principal of nearest neighbors to create its synthetic data. Therefore, synthetic data generated is similar to the existing one.\n",
    "\n",
    "The purpose of over-sampling the minority label here is to balance out the labels distribution to prevent heavy bias of the model by avoiding feeding in dataset that is heavily bias at the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resample, y_resample = SMOTE().fit_sample(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': [487]\n",
      "Before OverSampling, counts of label '0': [283850]\n",
      "After OverSampling, counts of label '1': 283850\n",
      "After OverSampling, counts of label '0': 283850\n"
     ]
    }
   ],
   "source": [
    "y_ar = np.array(y)\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_ar==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y_ar==0)))\n",
    "\n",
    "y_resample_ar = np.array(y_resample)\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_resample_ar==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_resample_ar==0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_ostrain, X_ostest, y_ostrain, y_ostest = train_test_split(X_resample, y_resample, train_size=0.8, random_state=8606)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "454160/454160 [==============================] - 4s 10us/step - loss: 0.0370 - accuracy: 0.9876\n",
      "Epoch 2/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0104 - accuracy: 0.9973\n",
      "Epoch 3/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0080 - accuracy: 0.9980\n",
      "Epoch 4/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0068 - accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0052 - accuracy: 0.9989\n",
      "Epoch 8/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "454160/454160 [==============================] - 4s 10us/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "454160/454160 [==============================] - 4s 9us/step - loss: 0.0044 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1949a704e10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model1.fit(X_ostrain, y_ostrain , batch_size = 150, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2019/10/Backpropagation.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[56614   123]\n",
      " [    0 56803]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = model1.predict(X_ostest)\n",
    "y_actual = pd.DataFrame(y_ostest)\n",
    "cnf_matrix = confusion_matrix(y_actual, y_hat.round())\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0 ,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TN** **FP**\n",
    "\n",
    "**FN** **TP**\n",
    "\n",
    "**FP** = Actual is 0 or Non-Fraud **BUT** Predicted as 1 or Fraud\n",
    "\n",
    "**FN** = Actual is 1 or Fraud **BUT** Predicted as 0 or Non-Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a ML use case in fraud detection, lowering false negative is important because the Fraud or Compliance Team would like to prevent actual fraudulent transaction from being predicted or flagged as non-fraudulent.\n",
    "\n",
    "\n",
    "Through Over-Sampling, we have effectively enhanced the accuracy of the model and lowered the number of false negative. After optimization, the model is less likely to let a fraudulent transaction flows pass it without flagging it out correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this model is performing better after optimization, let's save it for future use.\n",
    "\n",
    "model.save('creditcard_fraud_MLmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets' Use Our Trained and Saved Model to Predict on the Future Unseen Data by Our Model = \"Next Day\" Credit Card Txn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextday = pd.read_csv('C:/data/creditcard_nextday_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "creditcard_fraud_MLmodel = load_model('creditcard_fraud_MLmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXNid</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TXNB0000001</td>\n",
       "      <td>85285</td>\n",
       "      <td>-7.030308</td>\n",
       "      <td>3.421991</td>\n",
       "      <td>-9.525072</td>\n",
       "      <td>5.270891</td>\n",
       "      <td>-4.024630</td>\n",
       "      <td>-2.865682</td>\n",
       "      <td>-6.989195</td>\n",
       "      <td>3.791551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545698</td>\n",
       "      <td>1.103398</td>\n",
       "      <td>-0.541855</td>\n",
       "      <td>0.036943</td>\n",
       "      <td>-0.355519</td>\n",
       "      <td>0.353634</td>\n",
       "      <td>1.042458</td>\n",
       "      <td>1.359516</td>\n",
       "      <td>-0.272188</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TXNB0000002</td>\n",
       "      <td>68207</td>\n",
       "      <td>-13.192671</td>\n",
       "      <td>12.785971</td>\n",
       "      <td>-9.906650</td>\n",
       "      <td>3.320337</td>\n",
       "      <td>-4.801176</td>\n",
       "      <td>5.760059</td>\n",
       "      <td>-18.750889</td>\n",
       "      <td>-37.353443</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.493050</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>5.303607</td>\n",
       "      <td>-0.639435</td>\n",
       "      <td>0.263203</td>\n",
       "      <td>-0.108877</td>\n",
       "      <td>1.269566</td>\n",
       "      <td>0.939407</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TXNB0000003</td>\n",
       "      <td>94362</td>\n",
       "      <td>-26.457745</td>\n",
       "      <td>16.497472</td>\n",
       "      <td>-30.177317</td>\n",
       "      <td>8.904157</td>\n",
       "      <td>-17.892600</td>\n",
       "      <td>-1.227904</td>\n",
       "      <td>-31.197329</td>\n",
       "      <td>-11.438920</td>\n",
       "      <td>...</td>\n",
       "      <td>2.812241</td>\n",
       "      <td>-8.755698</td>\n",
       "      <td>3.460893</td>\n",
       "      <td>0.896538</td>\n",
       "      <td>0.254836</td>\n",
       "      <td>-0.738097</td>\n",
       "      <td>-0.966564</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-1.324884</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TXNB0000004</td>\n",
       "      <td>148053</td>\n",
       "      <td>1.261324</td>\n",
       "      <td>2.726800</td>\n",
       "      <td>-5.435019</td>\n",
       "      <td>5.342759</td>\n",
       "      <td>1.447043</td>\n",
       "      <td>-1.442584</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313332</td>\n",
       "      <td>0.209086</td>\n",
       "      <td>-0.425938</td>\n",
       "      <td>-0.154440</td>\n",
       "      <td>-0.018820</td>\n",
       "      <td>0.632234</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.468181</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TXNB0000005</td>\n",
       "      <td>14152</td>\n",
       "      <td>-4.710529</td>\n",
       "      <td>8.636214</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>10.313349</td>\n",
       "      <td>-4.351341</td>\n",
       "      <td>-3.322689</td>\n",
       "      <td>-10.788373</td>\n",
       "      <td>5.060381</td>\n",
       "      <td>...</td>\n",
       "      <td>1.434240</td>\n",
       "      <td>1.990545</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.554408</td>\n",
       "      <td>-1.204042</td>\n",
       "      <td>-0.450685</td>\n",
       "      <td>0.641836</td>\n",
       "      <td>1.605958</td>\n",
       "      <td>0.721644</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>TXNB0000496</td>\n",
       "      <td>68071</td>\n",
       "      <td>-0.267213</td>\n",
       "      <td>1.009205</td>\n",
       "      <td>1.718694</td>\n",
       "      <td>1.228670</td>\n",
       "      <td>0.311115</td>\n",
       "      <td>0.276414</td>\n",
       "      <td>0.784522</td>\n",
       "      <td>-0.300109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415479</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>0.699042</td>\n",
       "      <td>-0.149920</td>\n",
       "      <td>0.129349</td>\n",
       "      <td>-0.511750</td>\n",
       "      <td>-0.310460</td>\n",
       "      <td>0.289243</td>\n",
       "      <td>-0.129766</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>TXNB0000497</td>\n",
       "      <td>68071</td>\n",
       "      <td>0.805575</td>\n",
       "      <td>-0.455369</td>\n",
       "      <td>0.484172</td>\n",
       "      <td>1.582539</td>\n",
       "      <td>-0.518802</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.069667</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174479</td>\n",
       "      <td>0.054837</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>-0.228589</td>\n",
       "      <td>0.115146</td>\n",
       "      <td>0.568956</td>\n",
       "      <td>-0.288434</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.050857</td>\n",
       "      <td>183.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>TXNB0000498</td>\n",
       "      <td>68071</td>\n",
       "      <td>-1.195739</td>\n",
       "      <td>0.222015</td>\n",
       "      <td>2.431456</td>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>1.001468</td>\n",
       "      <td>1.216941</td>\n",
       "      <td>-0.314560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140902</td>\n",
       "      <td>-0.091803</td>\n",
       "      <td>0.437858</td>\n",
       "      <td>-0.452955</td>\n",
       "      <td>-0.280455</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>-0.444794</td>\n",
       "      <td>-0.619290</td>\n",
       "      <td>-0.591947</td>\n",
       "      <td>87.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>TXNB0000499</td>\n",
       "      <td>68072</td>\n",
       "      <td>-1.238503</td>\n",
       "      <td>1.473031</td>\n",
       "      <td>0.714599</td>\n",
       "      <td>4.250126</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.369489</td>\n",
       "      <td>0.924734</td>\n",
       "      <td>-0.549203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.842358</td>\n",
       "      <td>0.288620</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>-1.294032</td>\n",
       "      <td>0.072253</td>\n",
       "      <td>-0.662857</td>\n",
       "      <td>0.157678</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>TXNB0000500</td>\n",
       "      <td>68072</td>\n",
       "      <td>-0.823806</td>\n",
       "      <td>1.441984</td>\n",
       "      <td>1.253371</td>\n",
       "      <td>1.211561</td>\n",
       "      <td>-0.049747</td>\n",
       "      <td>0.206406</td>\n",
       "      <td>0.415675</td>\n",
       "      <td>0.138771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436229</td>\n",
       "      <td>-0.062567</td>\n",
       "      <td>0.666637</td>\n",
       "      <td>-0.080471</td>\n",
       "      <td>0.124139</td>\n",
       "      <td>-0.435617</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.268851</td>\n",
       "      <td>-0.131721</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TXNid    Time         V1         V2         V3         V4  \\\n",
       "0    TXNB0000001   85285  -7.030308   3.421991  -9.525072   5.270891   \n",
       "1    TXNB0000002   68207 -13.192671  12.785971  -9.906650   3.320337   \n",
       "2    TXNB0000003   94362 -26.457745  16.497472 -30.177317   8.904157   \n",
       "3    TXNB0000004  148053   1.261324   2.726800  -5.435019   5.342759   \n",
       "4    TXNB0000005   14152  -4.710529   8.636214 -15.496222  10.313349   \n",
       "..           ...     ...        ...        ...        ...        ...   \n",
       "495  TXNB0000496   68071  -0.267213   1.009205   1.718694   1.228670   \n",
       "496  TXNB0000497   68071   0.805575  -0.455369   0.484172   1.582539   \n",
       "497  TXNB0000498   68071  -1.195739   0.222015   2.431456   0.120116   \n",
       "498  TXNB0000499   68072  -1.238503   1.473031   0.714599   4.250126   \n",
       "499  TXNB0000500   68072  -0.823806   1.441984   1.253371   1.211561   \n",
       "\n",
       "            V5        V6         V7         V8  ...       V20        V21  \\\n",
       "0    -4.024630 -2.865682  -6.989195   3.791551  ...  0.545698   1.103398   \n",
       "1    -4.801176  5.760059 -18.750889 -37.353443  ... -3.493050  27.202839   \n",
       "2   -17.892600 -1.227904 -31.197329 -11.438920  ...  2.812241  -8.755698   \n",
       "3     1.447043 -1.442584  -0.898702   0.123062  ...  0.313332   0.209086   \n",
       "4    -4.351341 -3.322689 -10.788373   5.060381  ...  1.434240   1.990545   \n",
       "..         ...       ...        ...        ...  ...       ...        ...   \n",
       "495   0.311115  0.276414   0.784522  -0.300109  ...  0.415479  -0.075780   \n",
       "496  -0.518802  0.089108   0.069667   0.022271  ...  0.174479   0.054837   \n",
       "497   0.798431  1.001468   1.216941  -0.314560  ... -0.140902  -0.091803   \n",
       "498   0.964714  0.369489   0.924734  -0.549203  ...  0.004087   0.088658   \n",
       "499  -0.049747  0.206406   0.415675   0.138771  ...  0.436229  -0.062567   \n",
       "\n",
       "          V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0   -0.541855  0.036943 -0.355519  0.353634  1.042458  1.359516 -0.272188   \n",
       "1   -8.887017  5.303607 -0.639435  0.263203 -0.108877  1.269566  0.939407   \n",
       "2    3.460893  0.896538  0.254836 -0.738097 -0.966564 -7.263482 -1.324884   \n",
       "3   -0.425938 -0.154440 -0.018820  0.632234  0.192922  0.468181  0.280486   \n",
       "4    0.223785  0.554408 -1.204042 -0.450685  0.641836  1.605958  0.721644   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495  0.699042 -0.149920  0.129349 -0.511750 -0.310460  0.289243 -0.129766   \n",
       "496  0.046158 -0.228589  0.115146  0.568956 -0.288434  0.023970  0.050857   \n",
       "497  0.437858 -0.452955 -0.280455  0.429851 -0.444794 -0.619290 -0.591947   \n",
       "498  0.842358  0.288620  0.201295 -1.294032  0.072253 -0.662857  0.157678   \n",
       "499  0.666637 -0.080471  0.124139 -0.435617 -0.303387  0.268851 -0.131721   \n",
       "\n",
       "     Amount  \n",
       "0      0.00  \n",
       "1      1.00  \n",
       "2      1.00  \n",
       "3      1.59  \n",
       "4      1.00  \n",
       "..      ...  \n",
       "495    0.01  \n",
       "496  183.53  \n",
       "497   87.91  \n",
       "498    3.78  \n",
       "499    1.00  \n",
       "\n",
       "[500 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PowerTransformer(copy=True, method='yeo-johnson', standardize=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.fit(nextday[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nextday['Log Amount'] = pt.transform(nextday[['Amount']])\n",
    "\n",
    "nextday[['Amount', 'Log Amount']].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextday = nextday.drop(['Amount'], axis = 1)\n",
    "nextday = nextday.drop(['Time'], axis = 1)\n",
    "nextday = nextday.set_index('TXNid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Saved Model to Predict on New Next Day Credit Card Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = creditcard_fraud_MLmodel.predict(nextday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pd.DataFrame(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge back the Predicted Outputs to Inputs for a Completed Txn Table to the Fraud Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud = y_hat.round()\n",
    "\n",
    "nextday = pd.concat([nextday.reset_index(drop=False), Fraud.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nextday = nextday.rename(columns={0: 'Fraud'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TXNid</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Log Amount</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TXNB0000001</td>\n",
       "      <td>-7.030308</td>\n",
       "      <td>3.421991</td>\n",
       "      <td>-9.525072</td>\n",
       "      <td>5.270891</td>\n",
       "      <td>-4.024630</td>\n",
       "      <td>-2.865682</td>\n",
       "      <td>-6.989195</td>\n",
       "      <td>3.791551</td>\n",
       "      <td>-4.622730</td>\n",
       "      <td>...</td>\n",
       "      <td>1.103398</td>\n",
       "      <td>-0.541855</td>\n",
       "      <td>0.036943</td>\n",
       "      <td>-0.355519</td>\n",
       "      <td>0.353634</td>\n",
       "      <td>1.042458</td>\n",
       "      <td>1.359516</td>\n",
       "      <td>-0.272188</td>\n",
       "      <td>-2.095766</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TXNB0000002</td>\n",
       "      <td>-13.192671</td>\n",
       "      <td>12.785971</td>\n",
       "      <td>-9.906650</td>\n",
       "      <td>3.320337</td>\n",
       "      <td>-4.801176</td>\n",
       "      <td>5.760059</td>\n",
       "      <td>-18.750889</td>\n",
       "      <td>-37.353443</td>\n",
       "      <td>-0.391540</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>5.303607</td>\n",
       "      <td>-0.639435</td>\n",
       "      <td>0.263203</td>\n",
       "      <td>-0.108877</td>\n",
       "      <td>1.269566</td>\n",
       "      <td>0.939407</td>\n",
       "      <td>-1.545798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>TXNB0000003</td>\n",
       "      <td>-26.457745</td>\n",
       "      <td>16.497472</td>\n",
       "      <td>-30.177317</td>\n",
       "      <td>8.904157</td>\n",
       "      <td>-17.892600</td>\n",
       "      <td>-1.227904</td>\n",
       "      <td>-31.197329</td>\n",
       "      <td>-11.438920</td>\n",
       "      <td>-9.462573</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.755698</td>\n",
       "      <td>3.460893</td>\n",
       "      <td>0.896538</td>\n",
       "      <td>0.254836</td>\n",
       "      <td>-0.738097</td>\n",
       "      <td>-0.966564</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-1.324884</td>\n",
       "      <td>-1.545798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TXNB0000004</td>\n",
       "      <td>1.261324</td>\n",
       "      <td>2.726800</td>\n",
       "      <td>-5.435019</td>\n",
       "      <td>5.342759</td>\n",
       "      <td>1.447043</td>\n",
       "      <td>-1.442584</td>\n",
       "      <td>-0.898702</td>\n",
       "      <td>0.123062</td>\n",
       "      <td>-2.748496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209086</td>\n",
       "      <td>-0.425938</td>\n",
       "      <td>-0.154440</td>\n",
       "      <td>-0.018820</td>\n",
       "      <td>0.632234</td>\n",
       "      <td>0.192922</td>\n",
       "      <td>0.468181</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>-1.349366</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TXNB0000005</td>\n",
       "      <td>-4.710529</td>\n",
       "      <td>8.636214</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>10.313349</td>\n",
       "      <td>-4.351341</td>\n",
       "      <td>-3.322689</td>\n",
       "      <td>-10.788373</td>\n",
       "      <td>5.060381</td>\n",
       "      <td>-5.689311</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990545</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.554408</td>\n",
       "      <td>-1.204042</td>\n",
       "      <td>-0.450685</td>\n",
       "      <td>0.641836</td>\n",
       "      <td>1.605958</td>\n",
       "      <td>0.721644</td>\n",
       "      <td>-1.545798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>TXNB0000496</td>\n",
       "      <td>-0.267213</td>\n",
       "      <td>1.009205</td>\n",
       "      <td>1.718694</td>\n",
       "      <td>1.228670</td>\n",
       "      <td>0.311115</td>\n",
       "      <td>0.276414</td>\n",
       "      <td>0.784522</td>\n",
       "      <td>-0.300109</td>\n",
       "      <td>0.394467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>0.699042</td>\n",
       "      <td>-0.149920</td>\n",
       "      <td>0.129349</td>\n",
       "      <td>-0.511750</td>\n",
       "      <td>-0.310460</td>\n",
       "      <td>0.289243</td>\n",
       "      <td>-0.129766</td>\n",
       "      <td>-2.087625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>TXNB0000497</td>\n",
       "      <td>0.805575</td>\n",
       "      <td>-0.455369</td>\n",
       "      <td>0.484172</td>\n",
       "      <td>1.582539</td>\n",
       "      <td>-0.518802</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.069667</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0.499768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054837</td>\n",
       "      <td>0.046158</td>\n",
       "      <td>-0.228589</td>\n",
       "      <td>0.115146</td>\n",
       "      <td>0.568956</td>\n",
       "      <td>-0.288434</td>\n",
       "      <td>0.023970</td>\n",
       "      <td>0.050857</td>\n",
       "      <td>1.308142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>TXNB0000498</td>\n",
       "      <td>-1.195739</td>\n",
       "      <td>0.222015</td>\n",
       "      <td>2.431456</td>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>1.001468</td>\n",
       "      <td>1.216941</td>\n",
       "      <td>-0.314560</td>\n",
       "      <td>0.253638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091803</td>\n",
       "      <td>0.437858</td>\n",
       "      <td>-0.452955</td>\n",
       "      <td>-0.280455</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>-0.444794</td>\n",
       "      <td>-0.619290</td>\n",
       "      <td>-0.591947</td>\n",
       "      <td>0.922919</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>TXNB0000499</td>\n",
       "      <td>-1.238503</td>\n",
       "      <td>1.473031</td>\n",
       "      <td>0.714599</td>\n",
       "      <td>4.250126</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.369489</td>\n",
       "      <td>0.924734</td>\n",
       "      <td>-0.549203</td>\n",
       "      <td>-1.264781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>0.842358</td>\n",
       "      <td>0.288620</td>\n",
       "      <td>0.201295</td>\n",
       "      <td>-1.294032</td>\n",
       "      <td>0.072253</td>\n",
       "      <td>-0.662857</td>\n",
       "      <td>0.157678</td>\n",
       "      <td>-0.901702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>TXNB0000500</td>\n",
       "      <td>-0.823806</td>\n",
       "      <td>1.441984</td>\n",
       "      <td>1.253371</td>\n",
       "      <td>1.211561</td>\n",
       "      <td>-0.049747</td>\n",
       "      <td>0.206406</td>\n",
       "      <td>0.415675</td>\n",
       "      <td>0.138771</td>\n",
       "      <td>0.416125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062567</td>\n",
       "      <td>0.666637</td>\n",
       "      <td>-0.080471</td>\n",
       "      <td>0.124139</td>\n",
       "      <td>-0.435617</td>\n",
       "      <td>-0.303387</td>\n",
       "      <td>0.268851</td>\n",
       "      <td>-0.131721</td>\n",
       "      <td>-1.545798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TXNid         V1         V2         V3         V4         V5  \\\n",
       "0    TXNB0000001  -7.030308   3.421991  -9.525072   5.270891  -4.024630   \n",
       "1    TXNB0000002 -13.192671  12.785971  -9.906650   3.320337  -4.801176   \n",
       "2    TXNB0000003 -26.457745  16.497472 -30.177317   8.904157 -17.892600   \n",
       "3    TXNB0000004   1.261324   2.726800  -5.435019   5.342759   1.447043   \n",
       "4    TXNB0000005  -4.710529   8.636214 -15.496222  10.313349  -4.351341   \n",
       "..           ...        ...        ...        ...        ...        ...   \n",
       "495  TXNB0000496  -0.267213   1.009205   1.718694   1.228670   0.311115   \n",
       "496  TXNB0000497   0.805575  -0.455369   0.484172   1.582539  -0.518802   \n",
       "497  TXNB0000498  -1.195739   0.222015   2.431456   0.120116   0.798431   \n",
       "498  TXNB0000499  -1.238503   1.473031   0.714599   4.250126   0.964714   \n",
       "499  TXNB0000500  -0.823806   1.441984   1.253371   1.211561  -0.049747   \n",
       "\n",
       "           V6         V7         V8        V9  ...        V21       V22  \\\n",
       "0   -2.865682  -6.989195   3.791551 -4.622730  ...   1.103398 -0.541855   \n",
       "1    5.760059 -18.750889 -37.353443 -0.391540  ...  27.202839 -8.887017   \n",
       "2   -1.227904 -31.197329 -11.438920 -9.462573  ...  -8.755698  3.460893   \n",
       "3   -1.442584  -0.898702   0.123062 -2.748496  ...   0.209086 -0.425938   \n",
       "4   -3.322689 -10.788373   5.060381 -5.689311  ...   1.990545  0.223785   \n",
       "..        ...        ...        ...       ...  ...        ...       ...   \n",
       "495  0.276414   0.784522  -0.300109  0.394467  ...  -0.075780  0.699042   \n",
       "496  0.089108   0.069667   0.022271  0.499768  ...   0.054837  0.046158   \n",
       "497  1.001468   1.216941  -0.314560  0.253638  ...  -0.091803  0.437858   \n",
       "498  0.369489   0.924734  -0.549203 -1.264781  ...   0.088658  0.842358   \n",
       "499  0.206406   0.415675   0.138771  0.416125  ...  -0.062567  0.666637   \n",
       "\n",
       "          V23       V24       V25       V26       V27       V28  Log Amount  \\\n",
       "0    0.036943 -0.355519  0.353634  1.042458  1.359516 -0.272188   -2.095766   \n",
       "1    5.303607 -0.639435  0.263203 -0.108877  1.269566  0.939407   -1.545798   \n",
       "2    0.896538  0.254836 -0.738097 -0.966564 -7.263482 -1.324884   -1.545798   \n",
       "3   -0.154440 -0.018820  0.632234  0.192922  0.468181  0.280486   -1.349366   \n",
       "4    0.554408 -1.204042 -0.450685  0.641836  1.605958  0.721644   -1.545798   \n",
       "..        ...       ...       ...       ...       ...       ...         ...   \n",
       "495 -0.149920  0.129349 -0.511750 -0.310460  0.289243 -0.129766   -2.087625   \n",
       "496 -0.228589  0.115146  0.568956 -0.288434  0.023970  0.050857    1.308142   \n",
       "497 -0.452955 -0.280455  0.429851 -0.444794 -0.619290 -0.591947    0.922919   \n",
       "498  0.288620  0.201295 -1.294032  0.072253 -0.662857  0.157678   -0.901702   \n",
       "499 -0.080471  0.124139 -0.435617 -0.303387  0.268851 -0.131721   -1.545798   \n",
       "\n",
       "     Fraud  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      1.0  \n",
       "4      1.0  \n",
       "..     ...  \n",
       "495    0.0  \n",
       "496    0.0  \n",
       "497    0.0  \n",
       "498    0.0  \n",
       "499    0.0  \n",
       "\n",
       "[500 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV for Fraud Team's Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = nextday.to_csv (r'C:\\Fraud_Team\\Fraud_2020/02/02.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize on Tableau for Fraudulent Transactions Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://github.com/cplim-84/Neural-Network/blob/master/Fraud%20Management%20on%20Tableau.PNG?raw=true\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<img src=\"https://github.com/cplim-84/Neural-Network/blob/master/Fraud%20Management%20on%20Tableau.PNG?raw=true\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You.\n",
    "\n",
    "For any questions or the dataset (file size exceeds upload limit), feel free to drop me an email cp.lim@outlook.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
